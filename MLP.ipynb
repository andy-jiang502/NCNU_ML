{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本的模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # 指定只是用第1塊GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料處裡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fileloader(PreData, LoaderName):\n",
    "    PurName, PreName=\"\", \"\"\n",
    "    \n",
    "    PurName += LoaderName\n",
    "\n",
    "    if  (PreData==0): PreName += '00Raw'\n",
    "    elif(PreData==1): PreName += '01Smo'\n",
    "    elif(PreData==2): PreName += '02Smo_Diff'\n",
    "    elif(PreData==3): PreName += '03Smo_SNV_Diff'\n",
    "    elif(PreData==4): PreName += '04Smo_MSC_Diff'\n",
    "    elif(PreData==5): PreName += '05Smo_SNV'\n",
    "    elif(PreData==6): PreName += '06Smo_MSC'\n",
    "        \n",
    "    Method_Name = PurName + PreName\n",
    "    all_df_Origin = pd.read_excel(os.getcwd()+\"/DataBase/\" + Method_Name + \".xlsx\")\n",
    "    Method_Name2= PurName + \",\" + PreName\n",
    "    return all_df_Origin, Method_Name2\n",
    "\n",
    "def LabelToInt(DataTable):\n",
    "    df=DataTable\n",
    "    df=df.drop(['No', 'Name', 'Time', 'Country', 'Area', 'Variety_0', 'Treatment', 'Baking', 'Flavor', 'Gram', 'Status'], axis=1)\n",
    "    print(np.unique(df['Variety']))\n",
    "    df['Variety']= df['Variety'].map({'阿拉比卡':0, '阿拉比卡&羅布斯塔':1, '羅布斯塔':2}).astype(int)\n",
    "    return df\n",
    "\n",
    "#Label & Features 切割\n",
    "def PartData(df):\n",
    "    ndarray = df.values   #取得數據轉值\n",
    "    Label = ndarray[:,0]     #取得Label資料\n",
    "    Features = ndarray[:,1:]  #取得Features資料\n",
    "    return Features,Label\n",
    "#資料比例設定\n",
    "def PartTable(DF):\n",
    "    Flag_Variety=np.unique(DF['Variety']) #確認要辨識的Label\n",
    "    print(Flag_Variety)\n",
    "    DV0, DV1, DV2=DF[(DF.Variety == Flag_Variety[0])], DF[(DF.Variety == Flag_Variety[1])], DF[(DF.Variety == Flag_Variety[2])]\n",
    "    #選取該Label的列表\n",
    "    Flag_0_Name, Flag_1_Name, Flag_2_Name=np.unique(DV0['Name']), np.unique(DV1['Name']), np.unique(DV2['Name'])\n",
    "    #3個Label各自對應的Name\n",
    "    cho_Flag_0 = np.random.choice(Flag_0_Name)          #Label=0 (羅布斯塔) 隨機選1個\n",
    "    cho_Flag_1 = np.random.choice(Flag_1_Name, size=3)  #Label=1 (阿拉比卡) 隨機選3個\n",
    "    cho_Flag_2 = np.random.choice(Flag_2_Name)          #Label=2 (混和咖啡) 隨機選1個(只有1個)\n",
    "    \n",
    "    mskTrain=((DF.Name == cho_Flag_0)| \n",
    "              (DF.Name == cho_Flag_1[0])| (DF.Name == cho_Flag_1[1])| (DF.Name == cho_Flag_1[2])|\n",
    "              (DF.Name == cho_Flag_2))\n",
    "    Train = DF[~mskTrain]\n",
    "    \n",
    "    mskTest=((DF.Name == cho_Flag_0)| \n",
    "             (DF.Name == cho_Flag_1[0])| (DF.Name == cho_Flag_1[1])| (DF.Name == cho_Flag_1[2]))\n",
    "    Test = DF[mskTest]\n",
    "    \n",
    "    mskException=(DF.Name == cho_Flag_2)\n",
    "    Exception = DF[mskException]\n",
    "    \n",
    "    return Train, Test, Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def CellSetting(InCell, OutCell):\n",
    "    #輸入 特徵欄位數(輸入神經元), 標籤欄位數(輸入神經元)\n",
    "    #輸出 神經元1, 神經元2, 神經元3\n",
    "    D1 = round(2 * math.sqrt((OutCell+2)*InCell))\n",
    "    D2 = round(math.sqrt((OutCell+2)*InCell)+2*math.sqrt(InCell/(OutCell+2)))\n",
    "    D3 = round(OutCell * math.sqrt(InCell/(OutCell+2)))\n",
    "    return D1,D2,D3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型的設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout, Input\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPModelCreate(InCell, D1, D2, D3, OutCell):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(InCell,)))  # 確保這裡是元組形式\n",
    "    model.add(Dense(units=D1,     kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=D2,     kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=D3,     kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=OutCell,kernel_initializer='uniform', activation='sigmoid'))\n",
    "    #OutCell為Label欄位數量\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# 模型訓練\n",
    "def ModelTrain(model, train_Features, train_Label):\n",
    "    train_history = model.fit(x=train_Features, y=train_Label, validation_split=0.1, epochs=16, batch_size=1,verbose=0, shuffle=True)\n",
    "    print(\"==========Train End==========\")\n",
    "    return model, train_history\n",
    "\n",
    "# 模型的預測結果 & 機率\n",
    "def ModelPrediction(model, Features):\n",
    "    prediction=np.argmax(model.predict(Features), axis=-1)\n",
    "    Predicted_Probability=model.predict(Features)\n",
    "    return prediction, Predicted_Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Main(PreData, LoaderName):\n",
    "    DataTable_0, Method_Name = Fileloader(PreData, LoaderName)\n",
    "    print('資料集設定：' + Method_Name)\n",
    "    #============================================= \n",
    "    DfTrain, DfTest, DfException=PartTable(DataTable_0)\n",
    "    #============================================= \n",
    "    DataTable_Train = LabelToInt(DfTrain)\n",
    "    DataTable_Test = LabelToInt(DfTest)\n",
    "    DataTable_Exception = LabelToInt(DfException)\n",
    "    #=============================================\n",
    "    train_Features, train_Label = PartData(DataTable_Train)\n",
    "    test_Features,  test_Label  = PartData(DataTable_Test)\n",
    "    Exception_Features,  Exception_Label  = PartData(DataTable_Exception)\n",
    "\n",
    "    train_Label, test_Label = pd.DataFrame(train_Label), pd.DataFrame(test_Label) \n",
    "    train_Label, test_Label = train_Label.align(test_Label, join='outer',fill_value = 0, axis=1)\n",
    "    train_Label, test_Label = train_Label.values, test_Label.values\n",
    "    #=============================================\n",
    "    train_Features, test_Features, Exception_Features = train_Features[:,:], test_Features[:,:], Exception_Features[:,:]\n",
    "    \n",
    "    minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1)) #設定資料範圍\n",
    "    minmax_scale.fit(train_Features)\n",
    "    train_Features=minmax_scale.transform(train_Features)       #將Features數值轉換至0~1之間\n",
    "    test_Features=minmax_scale.transform(test_Features)         #將Features數值轉換至0~1之間\n",
    "    Exception_Features = minmax_scale.transform(Exception_Features)    \n",
    "    #=============================================\n",
    "    InCell, OutCell = len(train_Features[0]), len(train_Label[0])\n",
    "    D1, D2, D3 = CellSetting(InCell, OutCell)\n",
    "\n",
    "    Model_Name=\"MLP\"\n",
    "    print('模型設定：' + Model_Name)\n",
    "\n",
    "    Model1 = MLPModelCreate(InCell, D1, D2, D3, OutCell)\n",
    "    Model2, Train_History= ModelTrain(Model1, train_Features, train_Label)\n",
    "    #=============================================\n",
    "    prediction, Predicted_Probability = ModelPrediction(Model2, test_Features)\n",
    "    \n",
    "    Test_Accuracy=accuracy_score(np.argmax(test_Label, axis=1), prediction)\n",
    "    print('準確率: %.3f' % Test_Accuracy)\n",
    "    scores = Model2.evaluate(x=test_Features, y=test_Label, verbose=1)\n",
    "    print('誤差值(test): %.3f' % scores[0], '評估標準值(test): %.3f' % scores[1])\n",
    "    #=============================================\n",
    "    Exception_prediction, Exception_Probability = ModelPrediction(Model2, Exception_Features)\n",
    "    \n",
    "    #=============================================\n",
    "    #Model2.save(os.getcwd()+\"/Model/\" + Model_Name + '_' + Method_Name+'.h5')\n",
    "    #print(\"Saved model to disk\")\n",
    "    #============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main(1, '咖啡粉')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
